# 用来配置 merge-seqfile 所需要的配置信息
# 此文件存放在HDFS上
###########################################################################
######################### CDH集群访问的 相关配置 #########################
# CDH 集群使用的安全策略，kerberos 或 simple
hadoop_security_authentication=kerberos
#hadoop_security_authentication=simple
# CDH 集群如果使用kerberos安全策略的话，kerberos的配置文件的位置
#krb5_conf=/etc/krb5.conf
krb5_conf=.\\conf\\krb5.conf
# 访问 CDH Hive 的用户、keytab文件位置
hive_user=mrdas@WY.CMDI.CMCC
#hive_user=hive@WY.CMDI.CMCC
#hive_keytab=C:\\Program Files\\MIT\\Kerberos\\mrdas-WY.keytab
hive_keytab=.\\conf\\mrdas-WY.keytab
# Hive中用来存放合并后的MRO数据的 数据库名
dbname=test_lkz
# Hive中用来存放合并后的MRO数据的 表名、表文件存放路径
tb_name=mro_dt_rec_test1_spark
# 描述日志的字段信息（作为构造Hive表的列的依据）文件所在位置
mroobj_json=.\\conf\\mro_field.json
tb_location=/test/test_lkz/test_lkz_mro_dt_rec_v4
tb_compress=SNAPPY
log_level=INFO

# 日志数据库访问方式
# could008
pgdb_ip=10.254.222.226
pgdb_port=5432
pgdb_user=zhangyan
pgdb_passwd=#Mrdas17P19!
pgdb_db=mlogdb

# ftp相关的配置文件路径
ftp_conf=.\\conf\\ftp-conf.properties

# 需要将整理的ftp文件放入此路径下，此路径结构为 省/日期/地市/基站id
ftp_dir_collating_source_dir=/test

province_name=shanghai

city_date_hour_conf_file_path=.\\conf\\city_date_hour.properties

city_date_hour_hdfs_path=/test/test_lkz_other/bigdata_comp_seqfiles_new

merge_hive_files=10


